{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "agedetection10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhijithneilabraham/ExploreML/blob/master/agedetection10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyPalQiaLf-m",
        "colab_type": "code",
        "outputId": "a0e4c578-f1dd-4163-8358-59e2a849636f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "!git clone https://github.com/Parasgr7/Age-Detection-Indian-Actors-"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Age-Detection-Indian-Actors-'...\n",
            "remote: Enumerating objects: 26096, done.\u001b[K\n",
            "remote: Total 26096 (delta 0), reused 0 (delta 0), pack-reused 26096\u001b[K\n",
            "Receiving objects: 100% (26096/26096), 57.17 MiB | 27.19 MiB/s, done.\n",
            "Resolving deltas: 100% (7405/7405), done.\n",
            "Checking out files: 100% (26550/26550), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAUE0SneL5gK",
        "colab_type": "code",
        "outputId": "cc36e5ec-6eb8-407d-a512-65b95e538c64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd Age-Detection-Indian-Actors-\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Age-Detection-Indian-Actors-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vwICNMTMlQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f10878d-9ff3-4ba0-de85-a94d95b1c2dd"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rH1yxA3VXOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "from cv2 import imread,resize\n",
        "from keras.optimizers import SGD, Adam, Adamax\n",
        "import cv2\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqqbx3PMNHa0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "bfef1d42-d518-49f4-d967-3ccaf580d861"
      },
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>377.jpg</td>\n",
              "      <td>MIDDLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17814.jpg</td>\n",
              "      <td>YOUNG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21283.jpg</td>\n",
              "      <td>MIDDLE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16496.jpg</td>\n",
              "      <td>YOUNG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4487.jpg</td>\n",
              "      <td>MIDDLE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID   Class\n",
              "0    377.jpg  MIDDLE\n",
              "1  17814.jpg   YOUNG\n",
              "2  21283.jpg  MIDDLE\n",
              "3  16496.jpg   YOUNG\n",
              "4   4487.jpg  MIDDLE"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DDEyPH-Nv_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = []\n",
        "for img_name in train.ID:\n",
        "    img_path ='Train/'+img_name\n",
        "    img = imread(img_path)\n",
        "    img = resize(img, (64,64))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img=cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
        "    img = img.astype('float32') # this will help us in later stage\n",
        "    temp.append(img)\n",
        "\n",
        "train_x = np.stack(temp)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhwuUI3BTD7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = []\n",
        "for img_name in test.ID:\n",
        "    img_path = 'Test/'+img_name\n",
        "    img = imread(img_path)\n",
        "    img = resize(img, (64,64))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img=cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
        "    img = img.astype('float32') # this will help us in later stage\n",
        "    temp.append(img)\n",
        "test_x = np.stack(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D176ntNT8Y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "train_x = train_x / 255.\n",
        "test_x = test_x / 255.\n",
        "train.Class.value_counts(normalize=True)\n",
        "\n",
        "lb = LabelEncoder()\n",
        "train_y = lb.fit_transform(train.Class)\n",
        "train_y = keras.utils.np_utils.to_categorical(train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Fefb3IUXAN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        },
        "outputId": "ad56e49c-50a4-468f-83c9-877b0a92db21"
      },
      "source": [
        "epochs = 15\n",
        "batch_size = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(32, (3, 3),  padding='valid',activation='relu', input_shape=(64,64,3)))\n",
        "\n",
        "model.add(Convolution2D(16, (3, 3), padding='valid',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Convolution2D(8, (3, 3), padding='valid',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "model.save_weights('weights.h5')\n",
        "model.load_weights('weights.h5')\n",
        "model.compile(optimizer=Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-9, amsgrad=False), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_x, train_y, batch_size=batch_size,epochs=epochs,verbose=1,validation_split=0.1)\n",
        "\n",
        "\n",
        "pred = model.predict_classes(test_x)\n",
        "pred = lb.inverse_transform(pred)\n",
        "\n",
        "test['Class'] = pred\n",
        "test.to_csv('sub.csv', index=False)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_41 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 60, 60, 16)        4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 30, 30, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 28, 28, 8)         1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 14, 14, 8)         0         \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 128)               200832    \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 207,899\n",
            "Trainable params: 207,899\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 17915 samples, validate on 1991 samples\n",
            "Epoch 1/15\n",
            "17915/17915 [==============================] - 4s 238us/step - loss: 0.9508 - acc: 0.5521 - val_loss: 0.9270 - val_acc: 0.5500\n",
            "Epoch 2/15\n",
            "17915/17915 [==============================] - 3s 163us/step - loss: 0.8858 - acc: 0.5786 - val_loss: 0.8829 - val_acc: 0.5445\n",
            "Epoch 3/15\n",
            "17915/17915 [==============================] - 3s 166us/step - loss: 0.8601 - acc: 0.5919 - val_loss: 0.8284 - val_acc: 0.6153\n",
            "Epoch 4/15\n",
            "17915/17915 [==============================] - 3s 162us/step - loss: 0.8042 - acc: 0.6291 - val_loss: 0.7899 - val_acc: 0.6459\n",
            "Epoch 5/15\n",
            "17915/17915 [==============================] - 3s 163us/step - loss: 0.7745 - acc: 0.6454 - val_loss: 0.7610 - val_acc: 0.6600\n",
            "Epoch 6/15\n",
            "17915/17915 [==============================] - 3s 163us/step - loss: 0.7490 - acc: 0.6588 - val_loss: 0.7630 - val_acc: 0.6529\n",
            "Epoch 7/15\n",
            "17915/17915 [==============================] - 3s 163us/step - loss: 0.7233 - acc: 0.6782 - val_loss: 0.7505 - val_acc: 0.6585\n",
            "Epoch 8/15\n",
            "17915/17915 [==============================] - 3s 164us/step - loss: 0.6969 - acc: 0.6906 - val_loss: 0.7494 - val_acc: 0.6831\n",
            "Epoch 9/15\n",
            "17915/17915 [==============================] - 3s 163us/step - loss: 0.6671 - acc: 0.7069 - val_loss: 0.7429 - val_acc: 0.6725\n",
            "Epoch 10/15\n",
            "17915/17915 [==============================] - 3s 164us/step - loss: 0.6470 - acc: 0.7187 - val_loss: 0.7884 - val_acc: 0.6725\n",
            "Epoch 11/15\n",
            "17915/17915 [==============================] - 3s 162us/step - loss: 0.6144 - acc: 0.7337 - val_loss: 0.7590 - val_acc: 0.6735\n",
            "Epoch 12/15\n",
            "17915/17915 [==============================] - 3s 161us/step - loss: 0.5827 - acc: 0.7536 - val_loss: 0.7723 - val_acc: 0.6876\n",
            "Epoch 13/15\n",
            "17915/17915 [==============================] - 3s 160us/step - loss: 0.5363 - acc: 0.7725 - val_loss: 0.8024 - val_acc: 0.6836\n",
            "Epoch 14/15\n",
            "17915/17915 [==============================] - 3s 161us/step - loss: 0.5047 - acc: 0.7873 - val_loss: 0.8039 - val_acc: 0.6781\n",
            "Epoch 15/15\n",
            "17915/17915 [==============================] - 3s 159us/step - loss: 0.4636 - acc: 0.8064 - val_loss: 0.9109 - val_acc: 0.6811\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}